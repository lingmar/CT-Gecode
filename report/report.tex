\documentclass[a4paper,11pt]{article}
\usepackage{float}
\usepackage{subfig}
\usepackage{fullpage}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
%\pgfplotsset{plot coordinates/math parser=false}
\usetikzlibrary{calc}
\usepackage{cwpuzzle}
\usepackage{astra}
%\usepackage{etoolbox}\AtBeginEnvironment{algorithmic}{\small‌​}
%\usepackage{algorithm2e}
%\usepackage{algorithmicx}
%\input{macros}

%\usepackage{amsthm}
\usepackage{amsthm}

\newtheorem{definition}{Definition}
%\newtheorem{proof}{Proof}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\newcommand{\CT}[0]{CT~}

% Silly but saves space
\newcommand{\T}[1]{\texttt{#1}}

\newcommand{\Timeout}{600.00} % CPU seconds
\newcommand{\Todo}[1]{{\color{blue}#1}}
\newcommand{\Secref}[1]{Section~\ref{#1}}
\newcommand{\Chapref}[1]{Section~\ref{#1}}
\newcommand{\Algoref}[1]{Algorithm~\ref{#1}}
\newcommand{\Table}{\Constraint{Table}~}
\newcommand{\Extensional}{\Constraint{Extensional}~}
\newcommand{\Lineref}[1]{Line~\ref{#1}}
\newcommand{\Linesref}[2]{Lines~\ref{#1}-\ref{#2}}
\newcommand{\lineref}[1]{line~\ref{#1}}
\newcommand{\linesref}[2]{lines~\ref{#1}-\ref{#2}}
\newcommand{\Defref}[1]{Definition~\ref{#1}}
\newcommand{\Thmref}[1]{Theorem~\ref{#1}}
\newcommand{\Lemmaref}[1]{Lemma~\ref{#1}}

\newcommand{\Reg}[0]{Reg~}
\newcommand{\Tups}[0]{Tup\_speed~}
\newcommand{\Tupm}[0]{Tup\_mem~}

\newcommand{\Eqref}[1]{\eqref{#1}}

\newcommand{\Method}[2]{\textbf{method~}\mathrm{{#1}}({#2})}
\newcommand{\MethodReturn}[3]{\textbf{method~}\mathrm{{#1}}({#2})\textbf{\ : \ {#3}}}
\newcommand{\Class}{\textbf{Class~}}
\newcommand{\Constructor}{\textbf{constructor~}}

\newcommand{\Dom}[1]{\text{dom}({#1})}
\newcommand{\Dominit}[1]{\underline{\text{dom}}(#1)}


%\newcommand{\Ceiling}[1]{\left\lceil#1\right\rceil}
%\newcommand{\Floor}[1]{\left\lfloor#1\right\rfloor}


% SparseBitSet
\newcommand{\Words}{\texttt{words}}
\newcommand{\Index}{\texttt{index}}
\newcommand{\Mask}{\texttt{mask}}
\newcommand{\Limit}{\texttt{limit}}
\newcommand{\SparseBitSet}{\texttt{SparseBitSet}}
\newcommand{\Offset}{\texttt{offset}}

% CT Propagator
\newcommand{\Scp}{\texttt{vars}}
\newcommand{\CurrTable}{\texttt{validTuples}}
\newcommand{\Sval}{\texttt{S^{val}}}
\newcommand{\Ssup}{\texttt{S^{sup}}}
\newcommand{\LastSizes}{\texttt{lastSize}}
\newcommand{\Supports}{\texttt{supports}}
\newcommand{\Residues}{\texttt{residues}}

% Pseduo code
\newcommand{\ForEach}[1]{\textbf{foreach } {#1} \textbf{ do }}
\newcommand{\ForEachTo}[3]{\textbf{foreach } {#1} \textbf{ from } {#2} 
  \textbf{ to } {#3} \textbf{ do }}
\newcommand{\ForEachDownTo}[3]{\textbf{foreach } {#1} \textbf{ from } {#2} 
  \textbf{ downto } {#3} \textbf{ do }}
\newcommand{\Break}{\textbf{break~}}
\newcommand{\While}[1]{\textbf{while~} {#1} \textbf{~do~}}

\renewcommand{\algorithmicforall}{\textbf{Method}}
\renewcommand{\algorithmicdo}{}
\renewcommand{\algorithmicwhile}{\textbf{foreach}}

\newcommand{\Func}[2]{\FORALL{#1(#2)}}
\newcommand{\FuncRet}[3]{\FORALL{#1(#2) \ : \ \textbf{#3}}}
\newcommand{\Endfunc}{\ENDFOR}
\newcommand{\To}{~\bf{to}~}
\newcommand{\Downto}{~{\bf{downto}}~}
\newcommand{\For}[3]{\FOR{${#1} \leftarrow {#2} \To {#3}$ \textbf{do}}}
\newcommand{\ForDown}[3]{\FOR{${#1} \leftarrow {#2} \Downto {#3}$ \textbf{do}}}
\newcommand{\FOREACH}[1]{\WHILE{{#1} \textbf{do}}}
\newcommand{\ENDFOREACH}{\ENDWHILE}

\renewcommand{\algorithmiccomment}[1]{\hfill // #1}
\def\PROCEDURE{\item[\textbf{PROCEDURE}]}
\def\FAILED{\textbf{FAILED}}
\def\NOFIX{\textbf{NOFIX}}
\def\FIX{\textbf{FIX}}
\def\SUBSUMED{\textbf{SUBSUMED}}
\def\FAIL{\textbf{FAIL}}
\def\bool{\mathit{bool}}
\def\StatusMessage{\mathit{StatusMessage}}
\def\FindSupport{\textsc{FindSupport}}
\def\RemoveSupport{\textsc{RemoveSupport}}
\def\Extensional{\textsc{Extensional}}
\def\CompactTable{\textsc{CompactTable}}
\def\UpdateTable{\textsc{UpdateTable}}
\def\FilterDomains{\textsc{FilterDomains}}
\def\FixDomains{\textsc{FixDomains}}
\def\InitialiseCT{\textsc{InitialiseCT}}
\def\IndexOfFixed{\mathit{index\_of\_fixed}}


\newcommand{\ITE}[3]{\text{\bf ~if~} #1 \text{\bf ~then~} #2 \text{\bf ~else~} #3 \text{\bf ~endif}}

\newcommand{\function}[1]{\mathrm{#1}}
\newcommand{\localvar}[1]{\mathit{#1}}

\newlength\myindent
\setlength\myindent{2em}
\newcommand\bindent{%
  \begingroup
  \setlength{\itemindent}{\myindent}
  \addtolength{\algorithmicindent}{\myindent}
}
\newcommand\eindent{\endgroup}

\newcommand{\INDSTATE}[1][1]{\STATE\hspace{#1\algorithmicindent}}
\newcommand{\INDRETURN}[1][1]{\STATE\hspace{#1\algorithmicindent}\textbf{return~}}
\newcommand{\INDIF}[2][1]{\STATE\hspace{#1\algorithmicindent}
  \textbf{if~}{#2}\textbf{~then}}
\newcommand{\INDELSE}[1][1]{\STATE\hspace{#1\algorithmicindent}\textbf{else~}}
\newcommand{\INDELSEIF}[2][1]{\STATE\hspace{#1\algorithmicindent}
  \textbf{else if~}{#2}\textbf{~then}}

\newcommand{\CTpaper}[0]{DBLP:conf/cp/DemeulenaereHLP16}

\numberwithin{equation}{section}

\title{\textbf{Implementation and Evaluation of a\\
    Compact Table Propagator in Gecode
  }
}

\author{Linnea Ingmar} % replace by your name(s)

%\date{Month Day, Year}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Introduction}
\label{intro}

% What is CP?
% What is a propagator?
% Gecode
% Goal

Constraint Programmint (CP) is a programming paradigm that is used for solving
combinatorial problems. Within the paradigm, a problem is
modelled as a set of \emph{constraints} on a
set of \emph{variables} that each can take on a number of
possible values. The possible values of 
a variable is called the \emph{domain} of the variable.
All the variables are to be assigned a value
from their domains, so that all the constraints of the problem
are satisfied. Additionally, in some cases the solution should not only
satisfy the set of constraints for the
problem, but also maximise or minimise some given function.


%A constraint solver (CP solver) is a software that solves constraint problems.
A solution to a constraint problem is found by generating a search
tree, branching on possible values for the variables. At each node
in the search tree, impossible values are filtered out from the domains
of the variables in a process called~\emph{propagation}, effectively
reducing the size of the search tree.
Each constraint is associated with a \emph{propagation algorithm},
called a~\emph{propagator},
that implements the propagation for that constraint by removing
values from the variables that are in conflict with the constraint.

The \Table constraint expresses the possible combinations of values
that the associated variables can take as a sequence of tuples.
Assuming finite domains, the \Table constraint can theoretically
encode any kind of constraint and is thus very powerful. 
The design of propagation algorithms for \Table is an active research field,
and several algorithms are known. In 2016, a new propagation algorithm for the \Table
constraint was published~\cite{\CTpaper}, called Compact Table (CT).
Preliminary results indicate that CT outperforms the previously known algorithms.

A constraint programming solver (CP solver) is a software that solves constraint problems.
\emph{Gecode}~\cite{Gecode} is a popular CP solver written in C++, and combines
state-of-the-art performance with modularity and extensibility.
Gecode has three existing propagation algorithms for~\Table.
Before this project there had been no attempt to implement CT in Gecode
and consequently its performance in Gecode was unknown. 
The purpose of this thesis is to implement CT in Gecode and to evaluate
and compare its performance with previously existing propagators for
the \Table constraint.
The results of the evaluation indicate that CT outperforms
the existing propagation algorithms in Gecode for \Table,
which suggests that CT should be included in the solver.

% In Constraint Programming (CP), every constraint is associated with a propagator
% algorithm. The propagator algorithm filters out impossible values for the variables
% related to the constraint. For the \Table constraint, several propagator
% algorithms are known. In 2016, a new propagator algorithm for the \Table
% constraint was published~\cite{\CTpaper}, called Compact Table (CT).
% Preliminary results indicate that CT outperforms the previously known algorithms.
% There has been no attempt to implement CT in the constraint solver Gecode~\cite{Gecode}, 
% and consequently its performance in Gecode is unknown.

\subsection{Goal}
\label{intro:goal}
The goal of this bachelor thesis is the design, documentation and implementation
of a CT propagator algorithm for the \Table constraint in Gecode,
and the evaluation of its performance compared to the existing propagators.

\subsection{Contributions}
\label{intro:contributions}

% \Todo{State the contributions, perhaps as a bulleted list, referring to the different
% parts of the paper, as opposed to giving a traditional outline. (As suggested
% by Olle Gallmo.)}

Now follows the contributions made by this bachelor thesis, which also works as a
description of the outline of the written dissertation.

%The contributions that this bachelor thesis with the following:

\begin{itemize}
  \item The preliminaries that are relevant for the rest of the dissertation
    are covered in \Secref{bg}.

  \item The algorithms presented in the paper that is the starting point of this 
    project~\cite{DBLP:conf/cp/DemeulenaereHLP16} 
    have been modified to suit the target constraint solver Gecode, and are presented and explained in 
    \Secref{sec:algorithms}.

  \item Several versions of the CT algorithm has been implemented in Gecode, and
    the implementation is discussed in \Secref{sec:implementation}.

  \item The performance of the CT algorithm has been evaluated,
    and the results
    are presented and discussed in \Secref{evaluation}.

  \item The conclusion of the project is that the results indicate
    that CT outperforms the existing propagation algorithms, which
    suggests that CT should be included in Gecode, this is discussed
    in \Secref{conclusions}.

  \item Several possible improvements and flaws have been detected in the current
    implementation that prevent the code to meet commercial standards, these
    are listed in \Secref{conclusions}.
        
\end{itemize}

\section{Background}
\label{bg}

% Definiera alla begrepp som används senare

This section provides a background that is relevant for the
following sections. It is divided into five parts: \Secref{bg:cp}
introduces Constraint Programming. \Secref{bg:gecode} gives an overview
of Gecode, a constraint solver. \Secref{bg:table} introduces the~\Table
constraint. \Secref{bg:ct} describes the main concepts of the Compact
Table (CT) algorithm. Finally, \Secref{bg:sbs} describes the main
idea of reversible sparse bit-sets,
a data structure that is used in the CT algorithm.

\subsection{Constraint Programming}
\label{bg:cp}
This section introduces the concept of Constraint Programming (CP).

Constraint Programming (CP) is a programming paradigm that is used for solving
combinatorial problems.
Within the paradigm, a problem is
modelled as a set of \emph{constrains} on a
set of \emph{variables} that each can take on a number of
possible values. The possible values of 
a variable is called the \emph{domain} of the variable.
All the variables are to be assigned a value
from their domains, so that all the constraints of the problem
are satisfied. Additionally, in some cases the solution should not only
satisfy the set of constraints for the
problem, but also maximise or minimise some given function.

A constraint solver (CP solver) is a software that solves constraint problems.
The solving of a problem consists of generating a search tree by branching
on possible values for the variables. At each node in the search tree,
the solver removes impossible values from the domains of the variables.
This filtering process is called \emph{propagation}. Each constraint is
associated with at least one propagator algorithm, whose task is to detect
and remove values from the domains of the variables
that can never participate in a solution, because assigning them to
the variables would violate the constraint,
effectively pruning the size of the search tree.

To build intuition and understand the ideas of CP,
the concepts can be demonstrated with logical puzzles. One such
puzzle is Kakuro, somewhat similar to the popular puzzle Soduko,
a kind of mathematical crossword where the "words" consist
of numbers instead of letters, see Figure~\ref{fig:kakuro}.
The game board consists of 
blank cells forming rows and columns, called \emph{entries}.
Each entry has a \emph{clue}, a prefilled number indicating the sum of that entry.
The size of the board can vary.
The objective is to fill
in digits from 1 to 9 inclusive into each cell such that for each entry,
the sum of all the digits in the entry is equal to the clue of that entry,
and such that each digit appears at most once in each entry.

\begin{figure}
  \centering
  \begin{minipage}{.45\textwidth}
    \begin{Kakuro}{6}{6}
      |  -   |<:9>  |<:26> |  -   |<:19> |<:5>  |  -   |.
      |<16:> |  7   |  9   |<4:9> |  3   |  1   |  -   |.
      |<23:> |  1   |  1   |  1   |  1   |  4   |  -   |.
      |  -   |<6:10>|  1   |  1   |  1   |<:14> |  -   |.
      |<24:> |  1   |  1   |  1   |  1   |  1   |  -   |.
      |<4:>  |  1   |  1   |<15:> |  1   |  1   |  -   |.
    \end{Kakuro}
  \end{minipage}
  \begin{minipage}{.45\textwidth}
    \PuzzleSolution
    %\PuzzleUnitlength=14pt
    %\footnotesize\sf
    \begin{Kakuro}{6}{6}
      |  -   |<:9>  |<:26> |  -   |<:19> |<:5>  |  -   |.
      |<16:> |  7   |  9   |<4:9> |  3   |  1   |  -   |.
      |<23:> |  1   |  1   |  1   |  1   |  4   |  -   |.
      |  -   |<10:6>|  1   |  1   |  1   |<:14> |  -   |.
      |<24:> |  1   |  1   |  1   |  1   |  1   |  -   |.
      |<4:>  |  1   |  1   |<15:> |  1   |  1   |  -   |.
    \end{Kakuro}
  \end{minipage}
  \caption{A Kakuro puzzle~\protect\footnotemark (left) and its solution (right).}
  \label{fig:kakuro}
\end{figure}

\footnotetext{From \emph{200 Crazy Clever Kakuro Puzzles - Volume 2}, LeCompte, Dave, 2010.}

A Kakuro puzzle can be modelled as a constraint satisfaction problem with one variable
for each cell, and the domain of each variable being the set $\Set{1,..,9}$.
The constraints of the problem is that the sum of the variables that
belong to a given entry must be equal to the clue for that entry, and the
values of the variables for each entry must be distinct.

An alternative way of phrasing the constraints of Kakuro, is for each entry
explicitly list all the possible combinations
of values that the variables in that entry can take.
For example, consider an entry of size 2 with clue 4. The only
possible combinations of values are $\Tuple{1,3}$ and $\Tuple{3,1}$, since
these are the only tuples of $2$ distinct digits whose sums are 
equal to~$4$. This way of listing the possible combinations of 
values for the variables is in essence the 
\Table~constraint -- the constraint that is
addressed in this thesis.

\Todo{Really solve the Kakuro in Figure \ref{fig:kakuro}. Kvällspyssel!}

\smallskip 

After gaining some intuition of CP, now follows some formal definitions.
The definitions are based on
\cite{SchulteCarlsson:FDsys}, \cite{Apt:constraintsBook}, and \cite{Gecode:MPG}.

\begin{definition}
  \label{def:constraint}
  \textbf{Constraint.} Consider a finite sequence of~$n$ 
  variables~$X = x_1,\ldots,x_n$, and a corresponding sequence of
  finite \emph{domains}~$D = D_1,\ldots,D_n$ ranging over integers,
  that are possible values for the
  respective variable. 
  For a variable~$x_i \in X$, its domain~$D_i$ is denoted 
  by~$dom(x_i)$.
  \begin{itemize}
    \item   A \emph{constraint}~$c$ on~$X$ is a relation, 
      denoted by~$rel(c)$. The associated variables~$X$ are denoted~$vars(c)$,
      and we call~$|vars(c)|$ the \emph{arity} of~$c$. The relation
      $rel(c)$ contains the set of~$n$-tuples that are allowed
      for~$X$, we call those~$n$-tuples \emph{solutions} to the constraint~$c$.
    \item   For an~$n$-tuple~$\tau = \Tuple{a_1,\ldots,a_n}$ associated with~$X$, we
      denote the~$i$th value of~$\tau$ by~$\tau[i]$ or~$\tau[x_i]$. The 
      tuple~$\tau$ is \emph{valid} for~$X$
      if and only if each value of~$\tau$ is in the domain of the corresponding
      variable: $\forall i \in 1 \ldots n, \tau[i] \in dom(x_i)$, or equivalently,
      $\tau \in D_1 \times \ldots \times D_n$.
    \item An~$n$-tuple~$\tau$ is a \emph{support} on a~$n$-ary constraint~$c$ if and only
      if~$\tau$ is valid for~$vars(c)$ and~$\tau$ is a solution to~$c$, that is,
      $\tau$ is contained in~$rel(c)$.
    \item For an~$n$-ary constraint~$c$, involving a variable~$x$ such that
      the value~$a \in dom(x)$, an~$n$-tuple~$\tau$ is a 
      \emph{support for}~$(x,a)$ on~$c$ if and only if~$\tau$ is a support on~$c$,
      and~$\tau[x] = a$.
    \end{itemize}
\end{definition}

Note that Definition~\ref{def:constraint} restricts the domains to range
over finite sets of integers. Constraints can be defined on
other sets of values, but in this thesis only finite integer domains
are considered.

\begin{definition}
  \textbf{CSP.} A Constraint Satisfaction Problem (CSP) is a 
  triple~$\left<V,D,C\right>$, where:
  $V = v_1, \ldots, v_n$ is a finite sequence of variables,
  ~$D = D_1, \ldots, D_n$ is a finite sequence of domains for the respective variable,
  and~$C = \Set{c_1, \ldots, c_m}$ is a set of constraints, each on a subsequence of~$V$.
\end{definition}

\begin{definition}
  \textbf{Stores.} A \emph{store}~$s$ is a function, mapping a finite set of
  variables~$V = v_1, \ldots, v_n$ to a finite set of domains. We denote the domain of
  a variable~$v_i$ under~$s$ by~$s(v_i)$ or~$\Dom{v_i}$.
  \begin{itemize}
    \item A store~$s$ is \emph{failed} if and only if~$s(v_i) = \varnothing$ for some~$v_i \in V$.
    \item   A variable~$v_i \in V$ is \emph{fixed}, or \emph{assigned},
      by a store~$s$ if and only if~$|s(v_i)| = 1$. 
    \item A store~$s$ is an \emph{assignment} store if all variables are 
      fixed under~$s$.

    \item Let~$c$ be an $n$-ary constraint on~$V$. A store~$s$ is 
      a \emph{solution store} 
      to~$c$ if and only if~$s$ is an assignment store and the
      corresponding~$n$-tuple is a solution to~$c$:
      $\forall i \in \Set{1,\ldots,n}, s(v_i) = \Set{a_i}$,
      and~$\left<a_1,\ldots,a_n\right>$ is a solution to~$c$.

    \item A store~$s_1$ is \emph{stronger} than a store~$s_2$, 
      written~$s_1 \preceq s_2$ if and only if~$s_1(v) \subseteq s_2(v)$ 
      for all~$v \in V$.
  \end{itemize}

\end{definition}

\subsection{Propagation and propagators}

Constraint propagation is the process of removing values from the domains
of the variables in a CSP that can never appear in a solution store to the 
CSP. In a CP solver, each constraint that the solver implements is associated with 
one or more propagation algorithms, called propagators, whose task is to remove
values that are in conflict with its respective constraint.

To have a well-defined behaviour of propagators, there are some properties that
they must fulfill. Now follows a definition of a propagator and the obligations
that they must meet, taken from \cite{SchulteCarlsson:FDsys} and \cite{Gecode:MPG}.

\begin{definition} \label{def:prop}
  \textbf{Propagators.} A \emph{propagator}~$p$ is a function mapping stores to stores:
  \begin{equation*}
    p: store \mapsto store
  \end{equation*}

  In a CP-solver, a propagator is implemented as a procedure that also returns 
  a \emph{status message}. A propagator must fulfill the following properties:

  \begin{itemize}
  \item A propagator~$p$ is a decreasing function:~$p(s) \preceq s$ for any store~$s$.
    This property guarantees that constraint propagation only removes values.

  \item A propagator~$p$ is a monotonic function:
    ~$s_1 \preceq s_2 \Rightarrow p(s_1) \preceq p(s_2)$
    for any stores~$s_1$ and~$s_2$. This property guarantees that constraint propagation
    preserves the strength-ordering of stores.

  \item A propagator is correct for the constraint it implements.
    A propagator~$p$
    is correct for a constraint~$c$ if and only if it does not
    remove values that are part of supports for~$c$.
    This property guarantees that a propagator does not miss any potential 
    solution store.

  \item A propagator is \emph{checking}: for a given assignment store~$s$, the propagator
    must decide whether~$s$ is a solution store or not for the constraint it
    implements. If~$s$ is a solution store, it must signal subsumption, otherwise
    it must signal failure.

  \item A propagator must be \emph{honest}: it must be 
    \emph{fixpoint honest} and \emph{subsumption honest}. 
    A propagator~$p$ is fixpoint honest if and only if it does not signal 
    fixpoint if it does not return a fixpoint, and it is subsumption honest
    if and only if it does
    not signal subsumption if it is not subsumed by an input store~$s$.
    
    A propagator~$p$ is at \emph{fixpoint} on a store~$s$ if and only if applying 
    $p$ to to~$s$ gives no further propagation:~$p(s) = s$ for
    a store~$s$. If a propagator~$p$ always returns a fixpoint, that is, 
    if~$p(s) = p(p(s))$, $p$ is \emph{idempotent}.

    A propagator is \emph{subsumed} by a store~$s$ if and only if
    all stronger stores are fixpoints:~$\forall s'\preceq s,p(s')=s$.

\end{itemize}

\end{definition}
Note that the honest property of a propagator does not mean that a
propagator is obliged to signal fixpoint or subsumption
if it has computed a fixpoint or is subsumed, only that it must not 
claim that it is at fixpoint or is subsumed if it is not. 
Thus, it is always safe 
(though in many cases not so efficient for the CP-solver)
for a propagator to signal 'not fixpoint', except for a solution store
when it must signal either fail or subsumption.
In fact, a propagator must not even prune values. An extreme case is
the identity propagator~$i$, with~$i(s) = s$ for all input stores~$s$,
which would be correct
for all constraints, as long at is it checking and honest.

The concept \emph{consistency level} gives a measure of how strong
the propagation of a propagator is.
There are three commonly used consistency levels,
\textbf{value consistency, bounds consistency}, and \textbf{domain consistency}.

% To give a measure of how strong the constraint propagation of a propagator
% is, it is common to declare a \emph{consistency level} of a propagator.

\begin{definition}
  \textbf{Bounds consistency.} A constraint~$c$ is bounds consistent on a store~$s$ 
  if and only if there exists at least one suppport for the lower and for the upper bound of
  each variable associated with~$c$: $\forall x \in vars(c)$,~$(x,\text{min}(\Dom{x}))$
  and~$(x,\text{max}(\Dom{x}))$ 
  have a support on~$c$.
  % A propagator~$p$ is bounds consistent, iff~$c$ is bounds consistent 
  % consistent on $p(s)$ for all stores~$s$ such that~$p(s)$ is not a failed store.
\end{definition}

\begin{definition}
  \textbf{Domain consistency.} A constraint~$c$ is domain consistent on a store~$s$ 
  if and only if there exists at least one support for all values of each variable
  associated with~$c$:
  $\forall x \in vars(c),$ and $\forall a \in \Dom{x}$,~$(x,a)$ 
  has a support on~$c$.
 % for all variable-value
 %  % pair~$(x,a)$ such that~$x \in vars(c)$ and~$a \in dom(x)$, there exists
 %  % at least one support for~$(x,a)$ on~$c$. 
 %  % % A propagator~$p$ is 
 %  domain consistent, iff~$c$ is domain 
  % consistent on $p(s)$ for all stores~$s$ such that~$p(s)$ is not a failed store.
\end{definition}

\Todo{Value consistency}.

Value consistency is weaker than bounds consistency, and bounds consistency
is weaker than domain consistency.

A propagator~$p$ is said to have a certain consistency level,
if applying~$p$ to any input store~$s$, the resulting store~$p(s)$
has that consistency level. Enforcing a stronger consistency level might 
remove more values from the domains of the variables, but might be
more costly.

The propagator that is concerned in this project is domain consistent.

\subsection{Gecode}
\label{bg:gecode}
Gecode~\cite{Gecode} (Generic Constraint Development Environment)
is a popular constraint programming solver written in C++,
distributed under the MIT license.
It has a state-of-the-art performance while being modular and extensible.
It supports the programming of new propagators, branching strategies,
and search engines. Furthermore, Gecode is well documented and comes
with a complete tutorial.


Programming a propagator in Gecode means implementing a C++ object
inheriting from the base class Propagator,
that complies to the correct interface.
The propagator can store any data structures as instance members,
for saving information about its state between executions.
The interface consists of 
the following parts~\cite{Gecode:MPG}.

\begin{description}
  \item[Posting.] 
    Typical tasks of the posting of the propagator include
    deciding whether the propagator really needs to be posted,
    performing some initial propagation and creating an
    instance of the propagator.
    
    The propagator must also \emph{subscribe} to its associated variables,
    subscribing to a variable ensures the propagator is scheduled
    for execution whenever the relevant modification event occurs
    for that variable. Subscription can also be handled via
    advisors, see below.

    % Posting a propagator requires a \emph{constraint post function},
    % a \emph{propagator post function} and a \emph{constructor}.
    % The task of each of them are as follows:
    % \begin{itemize}
    %   \item The constraint post function envokes an appropriate propagator post function
    %     -- this function can thus be used by several different propagators implementing
    %     the same constraint.
    %   \item Typical tasks for the propagator post function include deciding whether the propagator
    %     really needs to be posted, deciding whether a more efficient propagator can be posted
    %     instead, and last but not least invoking the constructor of the propagator.
    %   \item The constructor creates an instance of the propagator and creates \emph{subscriptions}
    %     to views. Subscribing to the views means the propagator is scheduled for execution whenever
    %     the domains of the views change.
    % \end{itemize}
  \item[Disposal.] The propagator must implement a dispose() method that
    returns the memory used by the propagator at disposal.

  \item[Copying.] During search the propagator needs to be copied. This is
    handled by the copy() method.

  \item[Cost computation.] Gecode schedules propagators for execution according
    to their estimated cost. Cheaper propagators execute before more expensive
    ones, based on the inutition that cheaper propagators might prune values
    or detect a failure early, so that more expensive propagators can take
    advantage, or not even need to be executed. Every propagator implements
    a cost() method that estimates the cost of executing that propagator.

  \item[Propagation.] The propagator implements a propagate() method
    that performs the pruning of values. This method must fulfill
    the obligations in Definition~\ref{def:prop}.

  \item[Rescheduling.] For various reasons, a propagator can be disabled,
    in which case it needs to be rescheduled at a later point, implemented
    by a reschedule() method.

\end{description}

% Modification event
% What is it?
% Which exist?

Gecode provides \emph{advisors} that can inform propagators about variable
modifications.
Using advisors is optional.
An advisor belongs to a propagator and can store information that is needed by
its propagator. The purpose of an advisor is to, as its name suggests, advise
the propagator of whether it needs to be executed or not. This works as follows.
Whenever the domain
of the variable(s) that an advisor is subscribed to changes, its advise()
method is executed. If the advisor detects that its propagator is still
at fixpoint, it should not schedule the propagator. If it is not at fixpoint,
or possibly not at fixpoint, the advisor must schedule its propagator for
execution. Similarly, the advisor can report failure or subsumption
if it detects a failure or that its propagator is subsumed. An advisor
is not allowed to modify the domains of the variables. 
Furthermore, the advise() method can access
the modification event that triggered its execution. 
For integer and boolean variables, some information about which values
have been removed is provided.

Search in Gecode is copy-based. Before making a desicion in the search tree, the
current node is copied, so that the search can continue from an equivalent 
state in case the decision fails, or in case more solutions are to be sought for.
This implies some concerns on memory usage of the stored data structures
of a propagator, since allocating memory and copying large data structures
is time consuming, and a too large memory usage is not desirable.

% Characteristicsco
% Copy based


% definiera de delar av Gecodes API som dyker upp senare, såsom propagate(), status messages
% använda inbyggda klasen BitSets?
%Här bör du bl.a. skriva allt som är relevant för resten av rapporten om Gecodes API. T.ex. de tre returvärdena som propagerare ska returnera, ungefär som du har skrivit i 3.2.3, fast utan det CT-specifika.

\subsection{The \Table Constraint}
\label{bg:table}
The \Table constraint, also called \Extensional,
explicitly expresses the possible combinations of values for the variables as a
sequence of $n$-tuples.

\begin{definition}
  \textbf{Table constraints.} A
  (positive\footnote{There are also negative table constraints, that list the forbidden tuples instead of the allowed tuples.})
  \emph{table constraint c} is a
  constraint such that~$rel(c)$ is defined explicitly by listing all the
  tuples that are solutions to~$c$.
\end{definition}

Theoretically, any constraint could be expressed using the~\Table constraint,
simply by listing all the allowed assigments for its variables, 
making the~\Table constraint a powerful constraint. However, typically
it is too memory consuming to represent a constraint in this way
(exponential space in the number of variables). Also, common constraints
typically have a certain structure (such as a linear constraint)
that is difficult to take advantage of if the constraint is represented
extensionally~\cite{SchulteCarlsson:FDsys}.

Nevertheless, the~\Table constraint is an important constraint.
\Todo{Typical use cases? Propagator algortihms?}

In Gecode, the \Table constraint is called \Extensional. Gecode provides
three propagators for \Extensional, one where the possible solutions are
represented as a DFA, based on~\cite{Pesant:seqs}, and two where the solutions
are representad in a tuple set, which is a data structure in Gecode for representing 
a set of tuples. Among the last two one of them is based 
on~\cite{DBLP:journals/ai/BessiereRYZ05}, and consumes less memory than the
other, which is more incremental. 


\subsection{Compact-Table Propagator}
\label{bg:ct}
% Beskriv huvudidéerna
% Komplexitet? Kolla artikeln om negativa table-villkor
% O(r*d*t) per table constraint along a branch in the search tree (artikeln om bakgrund)
The compact table (CT) algorithm is a domain consistent propagation algorithm
that implements the \Table~constraint. It was first implemented in
OR-tools, a constraint solver, where it outperforms all previously
known algorithms. It was first described in~\cite{\CTpaper}.
Before this project, no attempts to implement CT in Gecode were made,
and consquently its performance in Gecode is unknown.

Compact table relies on bitwise operations using a new datastructure
called \emph{reversible sparse bit-set} (see \Secref{bg:sbs}).
The propagator maintains a reversible sparse bit set object, \texttt{currTable},
which stores the indices of the current valid tuples in a bit-set.
Also, for each variable-value pair, a bit-set mask is computed, that stores the
indices of the tuples that are supports for that variable-value pair.
These bit-set masks are stored in an array, \texttt{supports}.

Propagation consists of two steps:

\begin{enumerate}
  \item Updating \texttt{currTable} so that it only contains indices
    of valid tuples.
  \item Filtering out inconsistent values from the domains of each
    variable, that is,
    values that no longer have a tuple that supports it.
\end{enumerate}

Both steps rely heavily on bitwise operations on \T{currTable} and
\T{supports}. CT is discussed more deeply in \Secref{sec:algorithms}.

\subsection{Reversible Sparse Bit-Sets}
\label{bg:sbs}
% Beskriv idén
Reversible sparse bit-sets~\cite{\CTpaper} 
is a data structure for storing 
a set of values. It avoids performing operations on zero
words, which makes it efficient to perform bit-wise operations
with other bit-sets (such as intersecting and unioning)
even though the bit-set is sparse.

A reversible sparse bit-set has an array of ints, \T{words},
that are the actual stored bits, an array \T{index} that
keeps track of the indices of the non-zero words, and an
int \T{limit} that is the index of the last non-zero word
in \T{index}. Also, it has a temporary mask (array of ints)
that is used to modify \T{words}.

Some CP-solvers (Gecode is not among them)
use a mechanism called \emph{trailing} to perform backtracking,
where the main idea is to store a stack of operations that can
be undone upon backtrack. These CP-solvers typically expose
some "reversible" objects to the users using this mechanism,
among them the reversible version of the primitive type int.
The first word of the name of the datastructure comes from
the assumption that \T{words} consists of
reversible ints.

In what follows, a data structure that is 
like reversible sparse bit-sets except that it consists 
of ordinary ints and not reversible ints
will be called a sparse bit-set. Sparse bit-sets are discussed
in \Secref{sec:algorithms}.

% Reversiblity
% Trail based
% Reversible longs

\section{Algorithms}
\label{sec:algorithms}

% Section 3 bör beskriva din design i detalj men samtidigt inte på C++-nivå. Jag gillar att se sjok av pseudokod inbäddade i text som förklarar pseudokoden. Man kan skriva text mellan sjoken och/eller i caption till algorithm-omgivningen. Något som jag också gillar är stepwise refinement, dvs. att först visa en enkel men korrekt version, och sedan en eller flera mer sofistikerade, optimerade versioner. Den pseudokod som du har skrivit passar bra i Section 3, men bryt gärna upp åtminstone Class CT-Propagator i flera stycken algorithm-omgivningar.

This chapter presents the algorithms that are used in the implementation of the
CT propagator in \Chapref{sec:implementation}. In what follows, when we refer to
an array~$a$,~$a[0]$ denotes the first element (indexing starts from~$0$),
$a$.length() the number of its cells and~$a[i:j]$ all its cells in the closed
interval~$[i,j]$, where~$0 \leq i \leq j \leq a.\function{length}() - 1$.
% When we refer to a two-dimensional array~$m$,~$m[i][*]$ denotes
% row~$i$ and~$m[*][j]$ column~$j$, seeing~$m$ as a matrix.

\subsection{Sparse Bit-Set}
\label{sec:sbs}
This section describes Class~$\SparseBitSet$, which is the main data-structure
in the CT algorithm for maintaining the supports.~\Algoref{algo:sparse} shows the
pseudo code for Class~$\SparseBitSet$. The rest of this section describes its
fields and methods in detail.

\begin{algorithm}[H]
  \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
    \input{Class-SparseBitSet.tex}
    \end{algorithmic}
  \caption{Pseudo code for Class SparseBitSet.}
  \label{algo:sparse}
\end{algorithm}

\subsubsection{Fields}
\label{sbs:fields}
% \Todo{It should not be neccassary to keep \Mask~as a field, as it is only used temporarily.
% Unneccessary to copy it every time.}

\Todo{Todo: Add examples.}

\Linesref{line:sbsfield:start}{line:sbsfield:end} of~\Algoref{algo:sparse} shows the fields
of Class~\SparseBitSet~and their types. Now follows a more detailed description of them.

\begin{itemize}
  \item \Words~is an array of~$p$ 64-bit words which defines the current value of the bit-set:
    the~$i$th bit of the~$j$th word is 1 if and only if the $(j-1) \cdot 64 + i$th element of
    the set is present. Initially, all words in this array have all their bits set to~$1$,
    except the last word that may have a suffix of bits set to~$0$. \Todo{Example.}

  \item \Index~is an array that manages the indices of the words in~\Words,
    making it possible to performing operations to non-zero words only.
    In~\Index, the
    indices of all the non-zero words are at positions less than or
    equal to the value of the field~\Limit, and the indices of the zero-words are
    at indices strictly greater than~\Limit. 

  \item \Limit~is the index of~\Index~corresponding to the last non-zero word in~\Words.
    Thus it is one smaller than the number of non-zero words in~\Words.

    % \Limit~is the largest index of~\Index~corresponding to a non-zero word
    % in~\Words.
    % \Todo{Not entirely true, because the indices of the non-zero words will
    %   still be "lying around" at indices $> \Limit$.
    %   But the point is that we only \emph{care} about indices 0..\Limit~in~\Index.
    % Should think of a better formulation.}
  \item \Mask~is a local temporary array that is used to modify the bits in~\Words.
    
    % collect elements with
    % the method addToMask(). It can be cleared with method clearMask(). 
    % A~\SparseBitSet can only be modified by means of the method intersectWithMask().
\end{itemize}

\noindent
The class invariant describing the state of the class is as follows:

\begin{alignat}{1}
  \label{eq:invariant}
  &\Index~\text{is a permutation of~} [0,\dots,p-1],\text{~and} \\
  &\forall i \in \Set{0,\dots,p-1}: i \leq \Limit \Leftrightarrow \Words[\Index[i]] \neq 0^{64}
\end{alignat}

%\begin{alignat}{1}
%   &\Index[0:\Limit]~\text{is a permutation of a subset of~} [0,\dots,p-1],\text{~and} \\
%   &\forall i \in \Set{0,\dots,\Limit}: \Words[\Index[i]] \neq 0^{64}
% \end{alignat}

\subsubsection{Methods}
We now describe the methods in Class~\SparseBitSet~in~\Algoref{algo:sparse}.

\begin{itemize}
  \item initSparseBitSet() in~\linesref{line:initsbs:start}{line:initsbs:end}
    initialises a sparse bit-set-object. It takes 
    the number of bits as an argument and initialises the fields
    described in~\ref{sbs:fields} in a straightforward way.

  \item isEmpty() in lines~\ref{line:isEmpty:1}-\ref{line:isEmpty:2} checks
    if the number of non-zero words is different from zero. If the limit is
    set to~$-1$, that means that all words are zero-words and the bit-set
    is empty.

  \item clearMask() in lines~\ref{line:clearMask:1}-\ref{line:reverse:4}
    reverses the bits in the temporary mask.

  \item reverseMask() in lines~\ref{line:reverse:1}-\ref{line:clearMask:4}
    clears the temporary mask. This means setting to~$0$ all words of~$\Mask$
    corresponding to non-zero words of~\Words.
    

  \item addToMask() in~\linesref{line:addToMask:1}{line:addToMask:4} collects
    elements to the temporary mask by applying a word-by-word logical bit-wise
    \emph{or} operation with a given bit-set (array of long).
    Once again, this operation is only applied to indices corresponding to
    non-zero words in~\Words.

  \item intersectWithMask() in~\linesref{line:intersect:1}{line:intersect:9}
    considers each non-zero word of~\Words~in turn
    and replaces it by its intersection with the corresponding word of~\Mask.
    In case the resulting new word is~$0$, it (its index) is swapped with
    (the index of) the last non-zero word, and~\Limit~is
    decreased by one.
    
    In~\Secref{sec:implementation} we will see that the implementation
    actually can skip~\lineref{line:intersect:8.5} because it is unneccesary
    to save the index of a zero-word in a copy-based solver such as Gecode.
    We keep this
    line here though, because otherwise the invariant in~\Eqref{eq:invariant} 
    would not hold.
    
  \item intersectIndex() in~\linesref{line:interIdx:1}{line:interIdx:7}
    checks whether the intersection of~\Words~and a given bit-set
    (array of long) is empty or not. For all non-zero words in~\Words,
    we perform a logical bit-wise \emph{and} operation 
    in line~\ref{line:interIdx:5} and return
    the index of the word if the intersection is non-empty. If the
    intersection is empty for all words,~$-1$ is returned.
\end{itemize}

\subsection{Compact-Table (CT) Algorithm}
\label{sec:ct}
The CT algortithm is a domain consistent propagation
algorithm for any \Table constraint~$c$. \Secref{ct:pseudo}
presents pseudo code for the CT algorithm and a few variants
and \Secref{sec:proof} proves that CT fulfills the propagator
obligations.

\subsubsection{Pseudo code}
\label{ct:pseudo}

When posting the propagator, the input is an initial table, that is
a list of tuples $T_0 = \Tuple{\tau_0, \tau_1, \ldots, \tau_{p_0-1}}$ of
length~$p_o$. In what follows, we call the \emph{initial valid table}
for~$c$ the subset~$T \subseteq T_0$ of size~$p \leq p_0$ where all
tuples are a support on~$c$ for the initial domains of~$vars(c)$.
For a variable~$x$, we distinguish between the \emph{initial domain}
~$\Dominit{x}$ and the \emph{current domain} $\Dom{x}$ or~$s(x)$.
In an abuse of notation, we denote~$x \in s$ for a variable
$x$ that is part of store~$s$. We denote~$s[x \mapsto A]$
the store that is like~$s$ except that the variable~$x$ is mapped
to the set~$A$.

The propagator state has the following fields.

\begin{itemize}
%\item $\Scp$, a list of variables representing~$vars(c)$.
  
  \item $\CurrTable$, a $\SparseBitSet$ object representing the current valid
    supports for~$c$. If the initial valid table for~$c$
    is $\Tuple{\tau_0, \tau_1, \ldots, \tau_{p-1}}$,
    then~$\CurrTable$ is a 
    $\SparseBitSet$ object of initial size~$p$, such that value~$i$
    is contained (is set to~$1$) if and only if the~$i$th tuple is valid:
    
    \begin{equation} \label{eq:currtable}
      i \in \CurrTable \ \Leftrightarrow \ \forall x \in vars(c): \tau_i[x] \in \Dom{x}
    \end{equation}

  \item $\Supports$, a static array of bit-sets representing
    the supports for each variable-value pair~$(x,a)$.
    %It represents the supports for each variable-value pair~$(x,a)$,
    %where~$x \in vars(c) \land a \in \Dom{x}$.
    %It is a static array of words~$\Supports[x,a]$, seen as bit-sets.
    The bit-set~$\Supports[x,a]$ is such that
    the bit at position~$i$ is set to~$1$ if and only if the 
    tuple~$\tau_i$ in the initial valid table of~$c$ is initially a support for~$(x,a)$:

    \begin{alignat}{1}
      \forall x \in vars(c): \ \forall a \in \Dominit{x}:& \\
      \Supports[x,a][i] = 1 &\quad \Leftrightarrow \\
      (\tau_i[x] = a \quad \land \quad
      \forall y \in vars(c): \ &\tau_i[y] \in \Dominit{y})
    \end{alignat}

    $\Supports$ is computed once during the initialisation of CT and then
    remains unchanged.
    
  \item $\Residues$, an array of ints such that for each variable-value pair~$(x,a)$,
    $\Residues[x,a]$ denotes the index of the word in~$\CurrTable$ where a support
    was found for~$(x,a)$ the last time it was sought for.

\end{itemize}

\Algoref{algo:CT} shows the CT algorithm. Lines 1-4 initialises the propagator
if it is being posted. CT reports failure in case a variable domain was
wiped out in \InitialiseCT or if $\CurrTable$ is empty, meaning no tuples are valid.
If the propagator is not being posted,
lines 6-9 call \UpdateTable() for all variables whose domains have changed
since last time. \UpdateTable() will remove from $\CurrTable$ the tuples that
are no longer supported, and CT reports failure if all tuples were removed.
If at least one variable was pruned, \FilterDomains() is
called, which will filter out values from the domains of the variables that
no longer have supports, enforcing domain consistency.
CT is subsumed if there is at most one unassigned variable
left, otherwise CT is at fixpoint.
The condition for fixpoint is correct because CT is idempotent,
which is shown in the proof of Lemma~\ref{lemma:idempotent}.
Why the condition for subsumption is correct is shown in the proof of 
Lemma~\ref{lemma:honest}.

\input{ct-functional.tex}

The initialisation of the fields is described in
\Algoref{algo:initialise-CT}. \InitialiseCT() takes the 
initial table~$\localvar{T_0}$ as argument.

\begin{algorithm}[H]
  \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
    \input{initialiseCT.tex}
  \end{algorithmic}
  \caption{Initialising the CT-propagator.}
  \label{algo:initialise-CT}
\end{algorithm}

\Linesref{line:init:-1}{line:init:0} perform simple bounds
  propagation to limit the domain sizes of the variables,
  which in turn will limit the sizes of the data structures.
  It removes
  from the domain of each variable~$x$ all values that are either greater 
  than the largest element or smaller than the smallest element in the
  initial table. If a variable has a domain wipe-out,~$Failed$ is returned.

\Linesref{line:init:3}{line:init:4}~initialise local variables that will be 
used later.

\Linesref{line:init:residue}{line:init:supports}~initialise the fields
~\Residues~and~\Supports.
The field \Supports~is initialised as an array of bit-sets, with one bit-set for each
variable-value pair, and the size of each
bit-set being the number of tuples in~$\localvar{tuples}$. Each bit-set is assumed
to be initially filled with zeros.

\Linesref{line:init:6}{line:init:7} set the correct bits to~$1$ in~$\Supports$.
For each tuple~$t$, we check if~$t$ is a valid support for~$c$. Recall that~$t$ is
a valid support for~$c$ if and only if~$t[x] \in \Dom{x}$ for all~$x \in scp(c)$.
We keep a counter,~$nsupports$, for the number of valid supports for~$c$.
This is used for indexing the tuples in~$\Supports$ (we only index the tuples
that are valid supports).
If~$t$ is a valid support,
all elements in~$\Supports$ corresponding to~$t$ are set to~$1$ in
line \ref{line:init:10}. We also take the opportunity to store the word index
of the found support in~$\Residues[x,t[x]]$
in line~\ref{line:init:11}.

\Linesref{line:init:12}{line:init:14} remove values that are not supported
by any tuple in the initial valid table. The procedure returns in case a variable
has a domain wipe out.

\Lineref{line:init:15} initialises~$\CurrTable$ as a~$\SparseBitSet$ object with
$nsupports$ bits, initially with all bits set to~$1$ since~$nsupports$
number of tuples are initially valid supports for~$c$.
At this point~$\localvar{nsupports} > 0$,
otherwise we would have returned at line~\ref{line:init:wipeout}.

  \begin{algorithm}[H]
  \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
    \input{updateTable.tex}
  \end{algorithmic}
  \caption{Updating the current table. The infrastructure
  is such that this procedure is called for each variable whose domain is
  modified since last time.}
  \label{algo:updateTable}
\end{algorithm}

  The procedure \UpdateTable() in~\Algoref{algo:updateTable}
  filters out (indices of)
  tuples that have ceased to be supports for the input variable~$x$.
  \Linesref{line:updateTable:5}{line:updateTable:6} stores the union of the
  set of valid tuples for each value~$a \in \Domain{x}$ in the temporary mask
  and \Lineref{line:updateTable:7} intersects~$\CurrTable$ with the mask,
  so that the indices that correspond to tuples that are no longer valid
  are set to~$0$ in the bit-set.
  % \Lineref{line:updateTable:8} checks whether the current table is empty,
  % in which case we return~$Failed$ in line~\ref{line:updateTable:9}
  % because there are no valid tuples left. 

  The algorithm is assumed to be run on an infrastructure that runs updateTable()
  for each variable~$x \in vars(c)$ whose domain has changed since last time.
  
  After the current table has been updated, inconsistent values must be removed
  from the domains of the variables.   
  It follows from the definition of the bit-sets~$\CurrTable$ and~$\Supports[x,a]$
  that~$(x,a)$ has a valid support if and only if 

  \begin{equation}
    \label{eq:validcond}
    (\CurrTable \Inter \Supports[x,a]) \neq \emptyset
  \end{equation}

  Therefore, we must check this condition for every variable-value pair~$(x,a)$ and
  remove~$a$ from the domain of~$x$ if the condition is not satisfied any more.
  This is implemented in \FilterDomains()
  in~\Algoref{algo:filterDomains}.%lines~\ref{line:filterDom:0}-\ref{line:filterDom:12}.

  \begin{algorithm}[H]
    \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
      \input{filterDomains.tex}
    \end{algorithmic}
    \caption{Filtering variable domains, enforcing domain consistency.}
        \label{algo:filterDomains}
  \end{algorithm}

  % \Lineref{line:filterDom:1} initialises a counter for the number of unassigned
  % variables.
  
  We note that it is only necessary to
  consider a variable~$x \in s$ such that~$s(x) > 1$,
  because we will never filter out values from the domain of an assigned
  variable. To see this, assume we removed the last value for a variable~$x$,
  causing a wipe-out for~$x$. Then by the definition in equation~\eqref{eq:currtable}
  \CurrTable~must be empty,
  which it will not be upon invocation of \FilterDomains, because then
  \CompactTable() would have reported failure. 
  %Hence, we need only consider~$x \in \Scp$ such that~$|\Dom{x} > 1|$.

  In \Linesref{line:filterDom:res1}{line:filterDom:res2} we check if the
  cached word index still has a support for~$(x,a)$. It it has not,
  we search for an index in line~\ref{line:filterDom:4} in~$\CurrTable$
  where a valid support for the variable-value pair~$(x,a)$ is found, 
  thereby checking the condition in~\eqref{eq:validcond}.
  If such an index exists, we cache it in~$\Residues[x,a]$, and
  if it does not, we remove~$a$ from~$\Dom{x}$ if~$(x,a)$ in 
  line~\ref{line:filterDom:7} since there is no support left for~$(x,a)$.

  % \Linesref{line:filterDom:8}{line:filterDom:9}
  % increments the counter of unassigned variables if~$|\Dom{x}| > 1$.

  % \Linesref{line:filterDom:10}{line:filterDom:11} return the correct
  % propagator status message. If the number of unassigned variables is
  % at most one, the propagator is subsumed. Otherwise, the propagator
  % is at fixpoint.


%\clearpage

%This description is mainly taken from~\cite{CTpaper}.

% Beskriv övergripande?

% CT is based on bitwise operations -- among the important datastructures we have
% a~$\SparseBitSet$ object which maintains the valid supports, and also a bitset
% matrix that

% In this ordered set, each tuple is indexed
% by the order it appears in the table, and the~$i$th element is~$1$ if and only if
% the~$i$th tuple is a valid support, else the~$i$th element is~$0$.

% \subsubsection{Fields}
% \label{CT:fields}

% \Todo{Add examples with figures for describing the fields.}

% % From hereon, we let the \emph{initial valid table} for $c$,~$T_v$, be a subset of the
% % initial table~$T$ such that for all tuples~$\tau \in T_v$, $\tau$ is a
% % support on~$c$. \Todo{Define: initial table.}
% \Linesref{line:CTfield:start}{line:CTfield:end} of \Algoref{algo:CT}
% shows the fields of Class \texttt{CT-Propagator} and their types.
% Now follows a more detailed description of them. In what follows, we let
% the~\emph{initial domain} of a variable~$x \in \Scp(c)$, denoted~$\Dominit{x}$,
% be the domain that~$x$ has before CT has performed any propagation,
% in contrast to~$\Dom{x}$ which is the current domain of~$x$.
% The \emph{initial table} for a table constraint~$c$ is the list of tuples
% $T_0 = \Tuple{\tau_0, \tau_1, \ldots, \tau_{p_0-1}}$ of length~$p_o$
% that are given as input to initCT(), and the
% \emph{initial valid table} for~$c$ is the subset $T \subseteq T_0$ of size~$p \leq p_0$
% such that~$\forall i \in \Set{1, \ldots, p_0}: \tau_i \in T$ iff $\tau_i$ 
% is a support on~$c$ for the initial domains of the variables. 

% \subsubsection{Methods}

% We now describe the methods of Class \texttt{CT-Propagator}.

% \paragraph{Initialisation.}

% \paragraph{Performing propagation.}
% When the propagator is invoked for propagation, the method propagate()
% in \Algoref{algo:CT} is called. Before defining this function, we need
% to define the help functions updateTable() and filterDomains().
% Performing propagation consists of two steps: updating the current
% table and filtering out inconsistent values from the domains of the variables.
% We now describe these processes in more detail.

% \begin{enumerate}
% \item \textit{Updating the current table.} 
  

% \item 
%   \textit{Filtering of domains.}
  
% \end{enumerate}

% After defining updateTable() and filterDomains(), we are now ready to
% define the method propagate() in Class CT-Propagator, shown 
% in~\Algoref{algo:propagate}.

% \Todo{It should be unneccessary to check if validTuples is empty
%   as that is done in updateTable already. However, when I try to
%   remove the check in the c++ code it crashes, maybe because of
%   synchronisation issues between advise() and propagate().}

% \begin{algorithm}[H]
%   \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
%     \input{propagate.tex}
%   \end{algorithmic}
%   \caption{Method propagate() in Class CT-Propagator. updateTable()
%     (\Algoref{algo:updateTable}) is
%   called, and if the current table is empty, we are in a failed node.
%   Otherwise, filterDomains() (\Algoref{algo:filterDomains})
%   is called, and the return value of that method is returned.}
%   \label{algo:propagate}
% \end{algorithm}

\paragraph{Optimisations.} If~$x$ is the only variable
that has been modified since the last invocation of~\CompactTable(),
it is not necessary to attempt to filter out values from~$x$, because
every value of of~$x$ will have a support in~$\CurrTable$.
Hence, in \Algoref{algo:filterDomains}, we only execute
\Linesref{line:filterDom:3}{line:filterDom:7} for~$s \setminus \Set{x}$.

\paragraph{Variants.}
The following lists some variants of the CT algorithm.
\newline 

\begin{description}
  \item[CT($\Delta$)] \emph{-- Using delta information in \UpdateTable().}
A variable $x$'s delta, $\Delta_x$, is the set of values that were removed from~$x$
since last time. If the infrastructure provides information about $\Delta_x$,
that information can be used in \UpdateTable(). \Algoref{algo:updateTableDelta}
shows a variant of~\UpdateTable() that uses delta information.
If~$\Delta_x$ is smaller than~$\Dom{x}$, we accumulate to the temporary mask
the set of invalidated tuples, and then reverse the temporary mask before
intersecting it with~$\CurrTable$.
\newline

\begin{algorithm}[H]
  \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
    \input{updateTableDelta.tex}
  \end{algorithmic}
  \caption{Updating the current table using delta information.}
  \label{algo:updateTableDelta}
\end{algorithm}

\item[CT($T$)]\emph{-- Fixing the domains when only one valid tuple left.} 
This variant is the only addition made to the algorithm presented in~\cite{\CTpaper}.
If only one valid tuple is left after all calls to \UpdateTable() are finished,
the domains of the variables can be fixed to the values for that tuple.
\Algoref{algo:propagateFix} shows an alternative to lines 10-11 in~\Algoref{algo:CT}.
This assumes that the propagator maintains an extra field~$T$ -- a list
of tuples representing the initial valid table for~$c$.

\begin{algorithm}[H]
  \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
    \input{propagateFix.tex}
  \end{algorithmic}
  \caption{Alternative to lines 10-11 in \Algoref{algo:CT}, assuming
  the initial valid table~$T$ is stored as a field.}
  \label{algo:propagateFix}
\end{algorithm}

For a word~$\texttt{w}$, there is exactly one bit set if and only if

\begin{equation*}
  \T{w} \neq 0 \quad \land \quad  (\T{w} \ \& \ (\T{w}-1)) \ = \ 0,
\end{equation*}

\noindent
a condition that can be checked in constant time.
This is implemented in~\Algoref{algo:one}, which returns
the bit index of the set bit if there is exactly one bit set, else $-1$.
The method IndexOfFixed() is added to Class \SparseBitSet and assumes access to
builtin~\textsc{MSB}~which returns the index of the most significant bit of a given int.

\begin{algorithm}[H]
  \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
    \input{one.tex}
  \end{algorithmic}
  \caption{Checking if exactly one bit is set in \SparseBitSet.}
  \label{algo:one}
\end{algorithm}

\end{description}
% \Algoref{algo:fixDomains} shows the procedure~\FixDomains() which is called in
% line~\Algoref{algo:proapgateFix} in case there is only one valid tuple left.
% We assume that the propagator status has
% the extra field $T$ -- a list of tuples representing the initial valid
% table for~$c$.

% \begin{algorithm}[H]
%   \begin{algorithmic}[1]  % comment [1] away to drop the line numbers
%     \input{fixDomains.tex}
%   \end{algorithmic}
%   \caption{Fixing the domains of the variables to the only valid tuple.}
%   \label{algo:propagateFix}
% \end{algorithm}

\subsubsection{Proof of properties for CT}
\label{sec:proof}
% TODO: konsekvent typsnitt på funktionsnamn
% TODO: initCT->initialiseCT

This section proves that the CT Propagator is indeed a well-defined propagator
implementing the~\Table~constraint. We formulate the following theorem, which
we will prove by a number of lemmas.

\begin{theorem} \label{thm:prop}
  CT is an idempotent, domain consistent propagator implementing 
  the~\Table~constraint, fulfilling the properties in~\Defref{def:prop}.
\end{theorem}

To prove~\Thmref{thm:prop}, we formulate and prove the following lemmas.
In what follows, we denote~$CT(s)$ the resulting store of executing
\CompactTable($s$) on an input store~$s$.

\begin{lemma} \label{lemma:decreasing}
  CT is a decreasing function.
\end{lemma}

\begin{proof}[Proof of \Lemmaref{lemma:decreasing}]
  Since $CT$ only removes values from
  the domains of the variables, we have $CT(s) \preceq s$ for any store $s$.
  Thus, $CT$ is a decreasing function.
\end{proof}

\begin{lemma}\label{lemma:idempotent}
  CT is idempotent.
\end{lemma}

\begin{proof}[Proof of \Lemmaref{lemma:idempotent}]
  To prove that $CT$ is idempotent, we shall show that $CT$ always reaches
  fixpoint for any input store~$s$, that is, $CT(CT(s)) = CT(s)$ for any
  store~$s$.

  Suppose $CT(CT(s)) \neq CT(s)$ for a store~$s$. 
  Since CT is monotonic
  and decreasing, we must have $CT(CT(s)) \prec CT(s)$, that is, $CT$
  must prune at least one value~$a$ from a variable~$x$ from the 
  store~$CT(s)$. 

  By \Eqref{eq:validcond}, there must exists at least one 
  tuple~$\tau_i$
  that is a support for~$(x,a)$ under the store $CT(s)$: 
  $\exists i: i \in \CurrTable \ \land \ \tau_i[x] = a$.
  After \T{updateTable()} is perfomed on~$CT(s)$, we still have
  ~$i \in \CurrTable$, because~$\tau_i$ is still valid in~$CT(s)$.
  Since~\T{filterDomains()} only removes values that have no supports,
  it is impossible that~$a$ is pruned from~$x$, since~$\tau_i$ is a
  support for~$(x,a)$. Hence, we must have~$CT(CT(s)) = CT(s)$.
\end{proof}

% \begin{proof}
%   CT can only remove values from the domains of the variables, it cannot
%   add values to the domains. Therefore, CT is a decreasing function.
% \end{proof}

\begin{lemma}\label{lemma:correct}
  CT is correct for the \Table constraint.
\end{lemma}

\begin{proof}[Proof of \Lemmaref{lemma:correct}]
  $CT$ does not remove values that participate in tuples that are supports
  on a \Table constratint~$c$,
  since \T{filterDomains()} and \T{initCT()} only removes values that 
  have no supports on~$c$. Thus,~$CT$ is correct for \Table.
\end{proof}

\begin{lemma}\label{lemma:checking}
  CT is checking.
\end{lemma}

\begin{proof}[Proof of \Lemmaref{lemma:checking}]
  For an input store~$s$ that is an assignment store, we shall show that $CT$
  signals failure if $s$ is not a solution store, and signals subsumption if
  $s$ is a solution store. 

  First, assume that~$s$ is not a solution store. That means that the tuple
  $\tau = \Tuple{s(x_1),\ldots,s(s_n)}~\notin~c$.
 
  There are two cases, either
  it is the first time $CT$ is applied or it has been applied before.
  If it is the first time, then \T{initCT()} is called.
  Since $\tau$ is not a solution to~$c$, there is at least one variable-value
  pair~$(x_i,s(x_i))$ which is not supported, so~$s(x_i)$ will be pruned
  from~$x$ in \T{initCT()}, which will report failure in line~\Lineref{line:init:wipeout}
  in~\Algoref{algo:initialise-CT}.
  
  If it is not the first time that $CT$ is called, \T{propagate()} is called.
  Since there are no valid tuples left, \CurrTable~will be empty after
  the call to \T{updateTable()} and $CT$ reports failure.
  
  Now assume that~$s$ is a solution store. 
  $CT$ signals subsumption in \T{filterDomains()} because all variables are assigned.

\end{proof}

\begin{lemma}\label{lemma:honest}
  CT is honest.
\end{lemma}

\begin{proof}[Proof of \Lemmaref{lemma:honest}]
  Since $CT$ is idempotent, $CT$ is fixpoint honest. It remains to show that
  $CT$ is subsumption honest.~$CT$ signals subsumption on input store~$s$
  if there is at most one
  unassigned variable~$x$ in~\T{filterDomains()}. After this point, no values will
  ever be pruned from~$x$ by~$CT$, because there will always be a support for
  $(x,a)$ for each value~$a \in dom(x)$. Hence,~$CT$ is indeed subsumed by~$s$
  when it signals subsumption.
    
\end{proof}

\begin{lemma}\label{lemma:domain-consistent}
  CT is domain consistent.
\end{lemma}

\begin{proof}[Proof of \Lemmaref{lemma:domain-consistent}]
  There are two cases; either it is the first time~$CT$ is called, or it
  is not. Both after a call to \T{initCT()} and \T{filterDomains()}, 
  for each variable-value
  pair~$(x,a)$ there exists at least one support, because we filter out those
  values that have no support.
\end{proof}

\begin{lemma}\label{lemma:monotonic}
  CT is a monotonic function.
\end{lemma}

\begin{proof}[Proof of \Lemmaref{lemma:monotonic}]
  Consider two stores~$s_1$ and~$s_2$ such that~$s_1 \preceq s_2$.
  Since~$CT$ is domain consistent, each variable-value pair $(x,a)$
  that is part of~$CT(s_1)$, must also be part of~$CT(s_2)$,
  so~$CT(s_1) \preceq CT(s_2)$.
\end{proof}


After proving Lemmas~\ref{lemma:decreasing}-\ref{lemma:monotonic},
proving~\Thmref{thm:prop} is trivial.

\begin{proof}[Proof of \Thmref{thm:prop}]
  The result follows by Lemmas~\ref{lemma:decreasing}-\ref{lemma:monotonic}.
\end{proof}

\section{Implementation}
\label{sec:implementation}

% Det här är vad jag hittar av värde när jag läser igenom OR-tools kod:

% De har två versioner av CT: en stor (antal tupler > 64) och en liten (antal tupler <= 64). Den lilla versionen drar nytta av att alla aktiva tupler kan representeras med bara ett 64-bitars ord istället för en array av 64-bitars ord. Då kan man till exempel skippa arrayen residues, och arrayen index i SparseBitSet. Osäker på hur stor nytta en sån förändring skulle göra.
% De allokerar arrayer som beror på domän-bredd och inte domän-storlek (för residues och supports), och lagrar initiala minsta domänvärdet för att indexera i dem, precis som jag gör i de fall jag inte använder en hashtabell. Eftersom de inte har en kopieringsbaserad lösare antar jag att det inte är ett problem i deras fall.
% I filterDomains har de några specialfall:
% x.size() == 2: kan titta på bara x.min() och x.max() och fixera x till rätt värde / rapportera fail om inget värde har stöd
% om x’s domän är ett sammanhängande intervall
% Resterande fall.
% I fall 2 och 3 ovan undviker de att använda motsvarande minus_v-operatorn (den som tar bort alla värden i en array) så långt som möjligt eftersom den är dyr, utan använder <=, >=-operatorn på de värden som ska tas bort på x’s gränser och minus_v bara på de värden som ska tas bort mitt i domänen. Jag tror det gäller i Gecode också att minus_v är dyr så det borde jag kunna använda.
% I updateTable har de det här specialfallet som jag kan använda: om variabeln x är fixerad till värdet a behöver jag inte allokera en temporär mask utan kan använda supports[x,a] direkt som mask.


% Section 4 blir nog mindre intressant än Section 3 och 5, men där kan du skriva om sånt som är specifikt för C++ och Gecode för att algoritmerna i Section 3 ska fungera, precis som du har börjat göra. Det är också en bra plats för detaljer som sopats under mattan i pseudokoden, t.ex. exakt hur du mappar (x,a) till rätt element i supports och residues, med hashtabell eller så.

This section describes an implementation of the CT propagator using the algorithms
presented in \Chapref{sec:algorithms}. The implementation was made in the C++ programming
language in the Gecode library.

\Todo{
  Describe
  \begin{itemize}
    \item Advisors
    \item Indexing of supports and residues
    \item Memory management
    \item Ideas from or-tools
    \item Profilation
  \end{itemize}
}

% The implementation uses advisors. Each advisor is responsible for one variable~$x$,
% and maintains supports information for that variable. The arrays $\Supports$
% and~$\Residues$ described in~\Secref{sec:ct} is thus split up in parts,
% one part per variable:
% call them~$\Supports_x$ and~$\Residues_x$. 
% How the indexing in~$\Supports_x$ and~$\Residues_x$ is done depends on how sparse
% the initial domain of~$x$ is. If the domain is sparse, a hash table is used

% \paragraph{Memory management}
% $\Supports$ is allocated in a shared memory space since it contains static data.
%All other data structures changes dynamically

% Can't modify the value of the variable while iterating over it
% when using an iterator for a view, the view cannot be modified (or, in C++ lingua: modifying the variable invalidates the iterator).

% The motivation to iterate over range sequences rather than individual values is efficiency:
% as there are typically less ranges than indvidual values, iteration over ranges can be more efficient.

% Sharing of domain and iterators (argument false in inter_v)

%http://www.gecode.org/doc/4.4.0/reference/classGecode_1_1Iter_1_1Values_1_1BitSet.html

% First perform bounds propagation

% Staging p. 324

% Region (memory allocation)

% Multimap for hashing rows?

\section{Evaluation}
\label{evaluation}
% TODO: skip crosswords
% TODO: appendix with plots

This chapter presents the evaluation of the implementation of the CT propagator
presented in \Chapref{sec:implementation}. 

\label{evaluation:setup}
The correctness of the CT propagator was validated with the existing unit tests
in Gecode for the \Table~constraint.

The benchmarks consist of \Todo{how many} series 
with a total of~$1507$ CSP instances that where used in the
experiments in~\cite{\CTpaper}.

\begin{table}[h]\small
  \caption{Benchmarks series and their characteristics.}
  \label{tab:benchmarks}
  \centering
  \begin{tabular}{lccc}  % right alignment --> decimal point alignment
    name & number of instances & arity & variable domains \\
    \midrule
    \input{benchmarks.tex} 
  \end{tabular}
\end{table}

All instances were written in MiniZinc~\cite{MiniZinc}, the
instances used in~\cite{\CTpaper} were originally written in XCSP2.1,
but compiled into MiniZinc. Of the~$1621$ instances that were used in~\cite{\CTpaper},
only~$1507$ could be used due to parse errors.
The benchmarks series and their characteristics are presented in Table~\ref{tab:benchmarks}.
The experiments were run
under Gecode 5.0 on 16-core machines with Linux Ubuntu 14.04.5 (64 bit),
Intel Xeon Core of~2.27~GHz, with~25~GB RAM and 8 MB L3 cache. The machines
were accessed via a shared server.

The performance of different versions of CT were compared, and the winning
version was compared against the existing propagators for
the \Table~constraint in Gecode.

The following section presents the results of the experiments.

First the results of comparing different versions of CT is presented,
and then the results of comparing the seemingly best version of CT with 
the existing propagators in Gecode for the~\Table constraint.


% In \Secref{evaluation:setup},
% the evaluation setup is described. In \Secref{evaluation:results} presents
% the results of the evaluation. The results are discussed in \Secref{evaluation:discussion}.



\subsection{Comparing different versions of CT}
\label{sec:compare}

\subsubsection{Evaluation Setup}
Four different versions of CT were compared.
The versions and their denotations are:

\begin{description}
  \item[CT] Basic version.
  \item[CT($\Delta$)] CT using $\Delta_x$, the set
    of values that has been removed from $\Dom{x}$
    since last time, as described in~\Algoref{algo:updateTableDelta}.
  \item[CT($T$)] CT that explicitly stores the initial valid table~$T$ as
    a field and
    fixes the domains of the variables to the last valid tuple, as described
    in~\Algoref{algo:propagateFix}.
  \item[CT($B$)] CT that during propagation reasons about the bounds of the domains before
    enforcing domain consistency, an implementation detail discussed in~\Secref{sec:implementation}.
\end{description}

\subsubsection{Results}

Each plot shows the number of instances solved as a function
of timeout limit in milliseconds.

\begin{figure}
  \begin{minipage}[b][10cm][s]{0.45\textwidth}
    \centering
    \vfill
    \begin{tikzpicture}[scale=0.8]
      \input{randsJC2500-compare.tex}
    \end{tikzpicture}
    \vfill
    \caption{\textbf{Rands JC2500.} }
    \vspace{\baselineskip}
  \end{minipage}\qquad
  \begin{minipage}[b][10cm][s]{0.45\textwidth}
    \centering
    \vfill
    \begin{tikzpicture}[scale=0.8]
      \input{randsJC5000-compare.tex}
    \end{tikzpicture}
    \vfill
    \caption{\textbf{Rands JC5000}. }
    \vspace{\baselineskip}
  \end{minipage}\qquad
  \begin{minipage}[b][10cm][s]{0.45\textwidth}
    \centering
    \vfill
    \begin{tikzpicture}[scale=0.8]
      \input{langford4-compare.tex}
    \end{tikzpicture}
    \vfill
    \caption{\textbf{Langford 4}.}
    \vspace{\baselineskip}
  \end{minipage}\qquad
  \begin{minipage}[b][10cm][s]{0.45\textwidth}
    \centering
    \vfill
    \begin{tikzpicture}[scale=0.8]
      \input{a5-compare.tex}
    \end{tikzpicture}
    \vfill
    \caption{\textbf{A5}.}
    \vspace{\baselineskip}
  \end{minipage}\qquad

\end{figure}

\begin{figure}
  \begin{minipage}[b][10cm][s]{0.45\textwidth}
    \centering
    \vfill
    \begin{tikzpicture}[scale=0.8]
      \input{TSP_Quat_20-compare.tex}
    \end{tikzpicture}
    \vfill
    \caption{\textbf{TSP Quat 20}.}
    \vspace{\baselineskip}
  \end{minipage}\qquad
  \begin{minipage}[b][10cm][s]{0.45\textwidth}
    \centering
    \vfill
    \begin{tikzpicture}[scale=0.8]
      \input{geom-compare.tex}
    \end{tikzpicture}
    \vfill
    \caption{\textbf{Geom}.}
    \vspace{\baselineskip}
  \end{minipage}\qquad
  \begin{minipage}[b][10cm][s]{0.45\textwidth}
    \centering
    \vfill
    \begin{tikzpicture}[scale=0.8]
      \input{Crosswords_lexVg-compare.tex}
    \end{tikzpicture}
    \vfill
    \caption{\textbf{Crosswords LexVG}.}
    \vspace{\baselineskip}
  \end{minipage} \qquad
\end{figure}

\subsubsection{Discussion}
\Todo{CT($\Delta$) outperforms the other variants.}

\subsection{Comparing CT against existing propagators for the~\Table constraint}

\subsubsection{Evaluation Setup}
The winning variant from the experiments in~\Secref{sec:compare},
CT($\Delta$), was compared against three existing propagators
in Gecode for the~\Table~constraint. The propagators are
denoted:

\begin{description}
  \item[CT] The Compact Table Propagator, version CT($\Delta$).
  \item[DFA] Layered graph (DFA) propagator, based on~\cite{Pesant:seqs}.
  \item[B] Basic positive tuple set propagator, based on~\cite{DBLP:journals/ai/BessiereRYZ05}.
  \item[I] Incremental positive tuple set propagator.
\end{description}

B is more memory-efficient than I, and I is expected to be faster than B.

\subsubsection{Results}
Each plot shows the number of instances solved as a function
of timeout limit in milliseconds.

\Todo{Change captions to DFA, B, I.}

\input{graphs.tex}

%\subsubsection{Discussion}

% Benchmarks: performance beroende på antalet variabler. 2-ställiga, 3-ställiga, ..., n-ställiga

% The set of 1,621 instances that were used for the experiments in~\cite{\CTpaper}
% were also used here. The instances were compiled (using~\cite{xcsp2mzn})
% from XCSP 2.1~\cite{DBLP:joxurnals/corr/abs-0902-2362} format 
% -- an XML based format to represent combinatorial constraint problems -- to
% MiniZinc~\cite{MiniZinc} -- a solver-independent constraint modeling language.
% \Todo{By various reasons, only X instances were used.} The instances were run
% once on a \todo{quantum computer} for every propagator and a timeout of
% 1,000 seconds was used.

Due to the high number of instances, the runtime for
each instance was only measured once. A timeout of 1000 seconds was used.

%\input{graphs.tex}





% \paragraph{Crosswords}
% Crosswords_lexVg
% Crosswords_wordsPuzzle
% Crosswords_wordsVg

% \paragraph{Travelling Salesman Problem}
% TSP_20
% TSP_25
% TSP_Quat_20


% a10
% a5
% aim-100-pos
% aim-200-pos
% aim-50-pos
% bddLarge
% bddSmall
% dubois
% geom
% k5_n10_d10_m15_p08

% \paragraph{Kakuro}
% kakuroext_easy
% kakuroext_hard
% kakuroext_medium

% \paragraph{Langford}
% langford2
% langford3
% langford4

% \paragraph{MDD}
% mdd05
% mdd07
% mdd09


% modRenault

% \paragraph{Nonograms}
% nonograms

% pigeonsplus

% \paragraph{Randomised instances}
% randsJC10000
% randsJC2500
% randsJC5000
% randsJC7500

% ssa

% \begin{table}[t] \tiny
%   \centering
%   \begin{tabular}{rrrrrrr}  % right alignment --> decimal point alignment
%     $n$ & $runtime_g$ & $fail_g$ & $nprops_g$ & $runtime_c$ & $fail_c$ & $nprops_c$ \\
%     \midrule
%     \input{results-crosswords.tex} % let your experiment script write directly
%                             % into this file, making sure every number
%                             % in a column has the _same_ number of decimals
%   \end{tabular}
%   \caption{}
%   \label{tab:res:sat}
% \end{table}


\subsection{Discussion}
\label{evaluation:discussion}



\section{Conclusions and Future Work}
\label{conclusions}

For the implementation to reach industry standard there
are a few things that need to be revised. The following lists some known
improvements and flaws.

\begin{itemize}
  \item There is an unfound error that causes a crash due to corrupt data 
    in very few cases.
    The most likely cause of this error is that some allocated memory area
    is too small, and that the data is modified outside of this area.
    
  \item Some memory allocations in the initialisation of the propagator
    depend on the domain widths rather
    than the domain sizes of the variables. This is unsustainable
    for pathological domains such as $\Set{1, 10^9}$. In the current
    implementation, a memory block of size~$10^9$ is allocated for this
    domain, but ideally it should not be neccassary to allocate more than~$2$
    elements. Though the problem seems trivial, it requires some
    work, because of indexing problems.

  \item The threshold value for when to use a hash table versus
    an array for indexing the supports should be calibrated with
    experiments.

  \item In the variant using delta information, the current implementation
    uses the incremental update if~$|\Delta_x| < |s(x)|$. It is possible
    that this condition can be generalised to~$|\Delta_x| < k \cdot |s(x)|$,
    where~$k \in \mathbb{R}$, something that remains to be investigated.

\end{itemize}

\bibliographystyle{abbrv}
\bibliography{astra,mybib}

% \appendix
% \section{Source Code}
% \label{sec:source-code}


% This appendix presents the source code for the implementation
% described in \Chapref{sec:implementation}.





\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

% OscaR source code:
% https://bitbucket.org/oscarlib/oscar/src/40e25aafba8f9b0ab06029449350a2a9d1614854/oscar-algo/src/main/scala/oscar/algo/reversible/ReversibleSparseBitSet.scala?at=dev&fileviewer=file-view-default
% https://bitbucket.org/oscarlib/oscar/src/40e25aafba8f9b0ab06029449350a2a9d1614854/oscar-cp/src/main/scala/oscar/cp/constraints/tables/TableCT.scala?at=dev&fileviewer=file-view-default3

% course note in constraint programming
% http://user.it.uu.se/~pierref/courses/COCP/slides/CourseNotes.pdf

% M-x reftex-parse-all
% F1 b
% M-x customize-group reftex

% Hash Functions
% https://en.wikipedia.org/wiki/Pairing_function
% https://www.cs.hmc.edu/~geoff/classes/hmc.cs070.200101/homework10/hashfuncs.html
% http://stackoverflow.com/questions/37918951/what-is-a-minimal-hash-function-for-a-pair-of-ints-that-has-low-chance-of-collis

